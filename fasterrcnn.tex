\documentclass{article}

\begin{document}


\setlength{\parindent}{6ex}

\begin{figure}
    \centering
    \includegraphics[width=0.50\textwidth]{models/fasterrcnn}
    \caption{Network of Faster R-CNN \cite{fasterrcnncite}. 
    Faster R-CNN is single and a unified network. The RPN extracts 
    region of interests (possible locations of objects in the given image) 
    from the extracted feature map from the given image. Then, the classifier 
    network operates on the final feature map to classify objects.}
    \label{fig:fasterrcnn1}
\end{figure}

\indent

Faster R-CNN \cite{fasterrcnncite} consists of a region proposal network and a detection network in which 
network is a single, unified network. 
The main improvement in Faster R-CNN is the shared convolutional layers between 
the RPN and the detection network as you can see in figure \ref{fig:fasterrcnn1}, so that, the cost of 
detection is drastically reduced. \par

The RPN provides a simultaneous prediction of object bounds and 
objectness scores. This is done by adding two convolutional layers after the 
shared convolutional layers. The first one converts extracted feature map into a 
feature vector and the second one generates an objectness score and regressed 
bounds for let's assume k region proposals as in figure \ref{fig:sliwinrpn1}. To 
generate region proposals, a small convolutional network slides over the shared 
feature map and each of these sliding windows is mapped to a lower-dimensional 
feature. \par

These k region proposals are fed into the detection network with the extraced feature 
map from shared convolutional layers. Then, the region of interest pooling extract 
region proposals from the extracted feature map. Predictions are made by using this 
final feature map. Thus, RPN says the detector network where to look. \par

Training of Faster R-CNN consists of four steps. First, RPN is trained. Since 
negative samples dominate positive samples in region proposals, 256 samples are 
sampled to train RPN by using mini-batches from a single image. Then, in the 
second step, Fast R-CNN is trained separately by using the region proposals 
generated by the RPN in step 1. So far, two networks are separate and they do 
not share convolutional layers. As a step 3, the shared convolutional layers are 
held fix and RPN is fine-tuned by using the detector network. As a final step, the 
layers of the detection network is fine-tuned by holding the shared convolutional layers 
fixed.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{sliwinrpn}
    \caption{Region Proposal Network (RPN) \cite{fasterrcnncite}. 
    RPN takes a convolutional feature map as input. Then, it outputs 
    a set of rectangular region proposals with objectness score.}
    \label{fig:sliwinrpn1}
\end{figure}

\end{document}